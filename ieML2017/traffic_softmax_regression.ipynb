{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import trafficDataUtility as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\KangYounKook\\\\Desktop\\\\ML_Study\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getDataFromFile  C:\\Users\\KangYounKook\\Desktop\\ML_Study\\sectionInfo.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "dataset = util.getDatasetFromFile(path+\"sectionInfo.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadDataFromFile  C:\\Users\\KangYounKook\\Desktop\\ML_Study\\PeriodTotalAverage.txt\n",
      "update Dataset [move_count,work_count,ratio]\n"
     ]
    }
   ],
   "source": [
    "filename = \"PeriodTotalAverage.txt\"\n",
    "util.updateDatasetFromFile(path+filename, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadCsvInput  C:\\Users\\KangYounKook\\Desktop\\ML_Study\\input10_all.csv\n"
     ]
    }
   ],
   "source": [
    "#filename = \"input\" + str(classes) +\"_all.csv\"\n",
    "filename = \"input10_all.csv\"\n",
    "data = util.loadCsvInput(path,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Section697 -------------------------\n",
      "accuracy: 0.745\n",
      "accuracy: 0.775744\n",
      "2 Section754 -------------------------\n",
      "accuracy: 0.679\n",
      "accuracy: 0.675057\n",
      "3 Section1212 -------------------------\n",
      "accuracy: 0.551\n",
      "accuracy: 0.517162\n",
      "4 Section852 -------------------------\n",
      "accuracy: 0.719\n",
      "accuracy: 0.704805\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "selectedList = ['Section697','Section754','Section1212','Section852']\n",
    "#for id in dataset.keys():\n",
    "for id in selectedList:\n",
    "\n",
    "    if id not in data.columns:\n",
    "        continue\n",
    "    if dataset[id][5] < 1440:\n",
    "        continue\n",
    "    Xa = util.getX(id,data,dataset)\n",
    "    if Xa is None:\n",
    "        continue\n",
    "    Ya = np.array(data[id]).reshape(-1,1)\n",
    "    num += 1\n",
    "    print(num, id, '-------------------------')\n",
    "#    Xn = np.c_[Xa[:1437],Xa[1:1438],Xa[2:1439]]\n",
    "    Xn = np.c_[Xa[:1437],Xa[1:1438]]\n",
    "    \n",
    "#    Xn = Xa[:1437]\n",
    "#    print(Xn.shape)\n",
    "    Yn = Ya[3:1440]\n",
    "#    print(Yn.shape)\n",
    "    \n",
    "    Xt = Xn[0:1000]\n",
    "    Xval = Xn[1000:1437]\n",
    "    Yt = Yn[0:1000]\n",
    "    Yval = Yn[1000:1437]\n",
    "    \n",
    "    input_size = 10\n",
    "    X = tf.placeholder(tf.float32, [None, input_size])\n",
    "    Y = tf.placeholder(tf.int32, [None, 1])\n",
    "    Y_one_hot = tf.one_hot(Y, classes)\n",
    "    Y_one_hot = tf.reshape(Y_one_hot, [-1, classes])\n",
    "\n",
    "    W = tf.Variable(tf.random_normal([input_size, classes]), name='weight')\n",
    "    b = tf.Variable(tf.random_normal([classes]), name='bias')\n",
    "\n",
    "    logits = tf.matmul(X, W) + b\n",
    "    hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "    cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    prediction = tf.argmax(hypothesis, 1)\n",
    "    correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(2000):\n",
    "            sess.run(optimizer, feed_dict={X:Xt, Y:Yt})\n",
    "#            if step % 2000 == 0:\n",
    "#                loss, acc = sess.run([cost,accuracy], feed_dict={X:Xt, Y:Yt})\n",
    "#                print(\"Step:{:5} Loss:{:.3f} Acc:{:.2%}\".format(step, loss, acc))\n",
    "        print('accuracy:', sess.run(accuracy, feed_dict={X:Xt,Y:Yt}))\n",
    "        print('accuracy:', sess.run(accuracy, feed_dict={X:Xval,Y:Yval}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preprocessing for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(input_size, classes):\n",
    "    X = tf.placeholder(tf.float32, [None, input_size])\n",
    "    Y = tf.placeholder(tf.int32, [None, 1])\n",
    "    Y_one_hot = tf.one_hot(Y, classes)\n",
    "    Y_one_hot = tf.reshape(Y_one_hot, [-1, classes])\n",
    "\n",
    "    W = tf.Variable(tf.random_normal([input_size, classes]), name='weight')\n",
    "    b = tf.Variable(tf.random_normal([classes]), name='bias')\n",
    "\n",
    "    logits = tf.matmul(X, W) + b\n",
    "    hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "    cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "    return hypothesis, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.contrib.lookup.index_table_from_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
