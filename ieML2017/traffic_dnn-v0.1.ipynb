{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "# weight\n",
    "# define cost/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\KangYounKook\\\\Desktop\\\\ML_Study\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KangYounKook\\Desktop\\ML_Study\\input1_7_2c.csv\n"
     ]
    }
   ],
   "source": [
    "#filename = \"input2_10c.csv\"\n",
    "#filename = \"input4_20_c.csv\"\n",
    "#filename = \"input2_5c.csv\"\n",
    "filename = \"input1_7_2c.csv\"\n",
    "fullname = path+filename\n",
    "print(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 7)\n"
     ]
    }
   ],
   "source": [
    "Xdata = np.array(data)\n",
    "print(Xdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720,)\n",
      "(720, 1)\n"
     ]
    }
   ],
   "source": [
    "ydata = np.array(data['Section760'])\n",
    "print(ydata.shape) \n",
    "ydata = ydata.reshape(-1,1)\n",
    "print(ydata.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ydata = np.c_[y1,y2]\n",
    "#ydata = np.c_[y1,y2,y3,y4]\n",
    "#ydata = np.c_[y2,y3]\n",
    "#print(ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = Xdata[:450]\n",
    "Xval = Xdata[450:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yt = ydata[1:451]\n",
    "yval = ydata[451:701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yt_1 = np.zeros((1000,2))\n",
    "#m = np.ones((1000,2))\n",
    "#yt_1 = yt-m\n",
    "#Xt1 = Xt[:,0:5]\n",
    "#Xt2 = Xt[:,5:10]\n",
    "#yt1 = yt[:,0:1]\n",
    "#yt2 = yt[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 7])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = 5\n",
    "Y_one_hot = tf.one_hot(Y, classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([7, 7]))\n",
    "#W1 = tf.get_variable(\"W1\", shape=[5,classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([7]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([7, 7]))\n",
    "#W2 = tf.get_variable(\"W2\", shape=[5,5], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([7]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([7, 5]))\n",
    "#W3 = tf.get_variable(\"W3\", shape=[5,5], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([5]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis,labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 4.994214111\n",
      "Epoch: 0002 cost= 1.401558585\n",
      "Epoch: 0003 cost= 1.235814916\n",
      "Epoch: 0004 cost= 1.199673904\n",
      "Epoch: 0005 cost= 1.187693967\n",
      "Epoch: 0006 cost= 1.190267430\n",
      "Epoch: 0007 cost= 1.194469849\n",
      "Epoch: 0008 cost= 1.184718728\n",
      "Epoch: 0009 cost= 1.185190558\n",
      "Epoch: 0010 cost= 1.183664415\n",
      "Epoch: 0011 cost= 1.183189260\n",
      "Epoch: 0012 cost= 1.183588929\n",
      "Epoch: 0013 cost= 1.182937304\n",
      "Epoch: 0014 cost= 1.184060640\n",
      "Epoch: 0015 cost= 1.186644885\n",
      "Epoch: 0016 cost= 1.182808598\n",
      "Epoch: 0017 cost= 1.182560364\n",
      "Epoch: 0018 cost= 1.182840122\n",
      "Epoch: 0019 cost= 1.183031930\n",
      "Epoch: 0020 cost= 1.182686302\n",
      "Epoch: 0021 cost= 1.182294726\n",
      "Epoch: 0022 cost= 1.182500376\n",
      "Epoch: 0023 cost= 1.182158218\n",
      "Epoch: 0024 cost= 1.182126469\n",
      "Epoch: 0025 cost= 1.181668533\n",
      "Epoch: 0026 cost= 1.181805743\n",
      "Epoch: 0027 cost= 1.182405353\n",
      "Epoch: 0028 cost= 1.182773166\n",
      "Epoch: 0029 cost= 1.181895547\n",
      "Epoch: 0030 cost= 1.180988842\n",
      "Epoch: 0031 cost= 1.182347920\n",
      "Epoch: 0032 cost= 1.181544436\n",
      "Epoch: 0033 cost= 1.181590186\n",
      "Epoch: 0034 cost= 1.181482659\n",
      "Epoch: 0035 cost= 1.180618299\n",
      "Epoch: 0036 cost= 1.180635969\n",
      "Epoch: 0037 cost= 1.181004339\n",
      "Epoch: 0038 cost= 1.181205604\n",
      "Epoch: 0039 cost= 1.181359516\n",
      "Epoch: 0040 cost= 1.180715124\n",
      "Epoch: 0041 cost= 1.179852962\n",
      "Epoch: 0042 cost= 1.180146456\n",
      "Epoch: 0043 cost= 1.179852578\n",
      "Epoch: 0044 cost= 1.180841035\n",
      "Epoch: 0045 cost= 1.180709865\n",
      "Epoch: 0046 cost= 1.181147416\n",
      "Epoch: 0047 cost= 1.179880659\n",
      "Epoch: 0048 cost= 1.179151151\n",
      "Epoch: 0049 cost= 1.179737369\n",
      "Epoch: 0050 cost= 1.179143164\n",
      "Epoch: 0051 cost= 1.179139137\n",
      "Epoch: 0052 cost= 1.179117521\n",
      "Epoch: 0053 cost= 1.179015477\n",
      "Epoch: 0054 cost= 1.178943091\n",
      "Epoch: 0055 cost= 1.178871393\n",
      "Epoch: 0056 cost= 1.178797073\n",
      "Epoch: 0057 cost= 1.178717613\n",
      "Epoch: 0058 cost= 1.178654750\n",
      "Epoch: 0059 cost= 1.178576178\n",
      "Epoch: 0060 cost= 1.178504613\n",
      "Epoch: 0061 cost= 1.178431710\n",
      "Epoch: 0062 cost= 1.178359932\n",
      "Epoch: 0063 cost= 1.178288062\n",
      "Epoch: 0064 cost= 1.178217742\n",
      "Epoch: 0065 cost= 1.178147647\n",
      "Epoch: 0066 cost= 1.178079168\n",
      "Epoch: 0067 cost= 1.178011828\n",
      "Epoch: 0068 cost= 1.177945548\n",
      "Epoch: 0069 cost= 1.177880618\n",
      "Epoch: 0070 cost= 1.177816722\n",
      "Epoch: 0071 cost= 1.177753886\n",
      "Epoch: 0072 cost= 1.177691711\n",
      "Epoch: 0073 cost= 1.177629961\n",
      "Epoch: 0074 cost= 1.177568144\n",
      "Epoch: 0075 cost= 1.177505838\n",
      "Epoch: 0076 cost= 1.177442511\n",
      "Epoch: 0077 cost= 1.177377568\n",
      "Epoch: 0078 cost= 1.177310454\n",
      "Epoch: 0079 cost= 1.177240438\n",
      "Epoch: 0080 cost= 1.177166873\n",
      "Epoch: 0081 cost= 1.177089161\n",
      "Epoch: 0082 cost= 1.177006483\n",
      "Epoch: 0083 cost= 1.176918070\n",
      "Epoch: 0084 cost= 1.176823298\n",
      "Epoch: 0085 cost= 1.176721162\n",
      "Epoch: 0086 cost= 1.176611026\n",
      "Epoch: 0087 cost= 1.176491936\n",
      "Epoch: 0088 cost= 1.176363018\n",
      "Epoch: 0089 cost= 1.176223305\n",
      "Epoch: 0090 cost= 1.176071763\n",
      "Epoch: 0091 cost= 1.175907360\n",
      "Epoch: 0092 cost= 1.175728970\n",
      "Epoch: 0093 cost= 1.175535348\n",
      "Epoch: 0094 cost= 1.175325195\n",
      "Epoch: 0095 cost= 1.175097254\n",
      "Epoch: 0096 cost= 1.174850106\n",
      "Epoch: 0097 cost= 1.174582468\n",
      "Epoch: 0098 cost= 1.174292962\n",
      "Epoch: 0099 cost= 1.173980594\n",
      "Epoch: 0100 cost= 1.173644410\n",
      "Epoch: 0101 cost= 1.173284186\n",
      "Epoch: 0102 cost= 1.172900081\n",
      "Epoch: 0103 cost= 1.172493670\n",
      "Epoch: 0104 cost= 1.172067298\n",
      "Epoch: 0105 cost= 1.171625151\n",
      "Epoch: 0106 cost= 1.171172579\n",
      "Epoch: 0107 cost= 1.170716299\n",
      "Epoch: 0108 cost= 1.170263780\n",
      "Epoch: 0109 cost= 1.169823103\n",
      "Epoch: 0110 cost= 1.169403010\n",
      "Epoch: 0111 cost= 1.169013460\n",
      "Epoch: 0112 cost= 1.168666350\n",
      "Epoch: 0113 cost= 1.168375770\n",
      "Epoch: 0114 cost= 1.168157180\n",
      "Epoch: 0115 cost= 1.168025944\n",
      "Epoch: 0116 cost= 1.167993837\n",
      "Epoch: 0117 cost= 1.168063058\n",
      "Epoch: 0118 cost= 1.168205857\n",
      "Epoch: 0119 cost= 1.168325411\n",
      "Epoch: 0120 cost= 1.168403241\n",
      "Epoch: 0121 cost= 1.168303317\n",
      "Epoch: 0122 cost= 1.167791592\n",
      "Epoch: 0123 cost= 1.166878104\n",
      "Epoch: 0124 cost= 1.165895581\n",
      "Epoch: 0125 cost= 1.165252580\n",
      "Epoch: 0126 cost= 1.165037513\n",
      "Epoch: 0127 cost= 1.165102575\n",
      "Epoch: 0128 cost= 1.165274117\n",
      "Epoch: 0129 cost= 1.165418519\n",
      "Epoch: 0130 cost= 1.165494813\n",
      "Epoch: 0131 cost= 1.165505740\n",
      "Epoch: 0132 cost= 1.165464057\n",
      "Epoch: 0133 cost= 1.165401207\n",
      "Epoch: 0134 cost= 1.165356384\n",
      "Epoch: 0135 cost= 1.165305628\n",
      "Epoch: 0136 cost= 1.165264606\n",
      "Epoch: 0137 cost= 1.165234089\n",
      "Epoch: 0138 cost= 1.165216022\n",
      "Epoch: 0139 cost= 1.165211479\n",
      "Epoch: 0140 cost= 1.165249997\n",
      "Epoch: 0141 cost= 1.165235135\n",
      "Epoch: 0142 cost= 1.165246182\n",
      "Epoch: 0143 cost= 1.165254659\n",
      "Epoch: 0144 cost= 1.165255732\n",
      "Epoch: 0145 cost= 1.165265163\n",
      "Epoch: 0146 cost= 1.165271282\n",
      "Epoch: 0147 cost= 1.165280991\n",
      "Epoch: 0148 cost= 1.165289415\n",
      "Epoch: 0149 cost= 1.165296727\n",
      "Epoch: 0150 cost= 1.165303773\n",
      "Epoch: 0151 cost= 1.165348331\n",
      "Epoch: 0152 cost= 1.165325059\n",
      "Epoch: 0153 cost= 1.165331258\n",
      "Epoch: 0154 cost= 1.165331946\n",
      "Epoch: 0155 cost= 1.165324489\n",
      "Epoch: 0156 cost= 1.165327536\n",
      "Epoch: 0157 cost= 1.165327377\n",
      "Epoch: 0158 cost= 1.165697151\n",
      "Epoch: 0159 cost= 1.167243322\n",
      "Epoch: 0160 cost= 1.170820687\n",
      "Epoch: 0161 cost= 1.171171798\n",
      "Epoch: 0162 cost= 1.171493239\n",
      "Epoch: 0163 cost= 1.170877126\n",
      "Epoch: 0164 cost= 1.170670165\n",
      "Epoch: 0165 cost= 1.170047402\n",
      "Epoch: 0166 cost= 1.169640541\n",
      "Epoch: 0167 cost= 1.169306397\n",
      "Epoch: 0168 cost= 1.168740723\n",
      "Epoch: 0169 cost= 1.168672403\n",
      "Epoch: 0170 cost= 1.168783598\n",
      "Epoch: 0171 cost= 1.169243852\n",
      "Epoch: 0172 cost= 1.169435395\n",
      "Epoch: 0173 cost= 1.169900404\n",
      "Epoch: 0174 cost= 1.170209673\n",
      "Epoch: 0175 cost= 1.169999692\n",
      "Epoch: 0176 cost= 1.169588725\n",
      "Epoch: 0177 cost= 1.169079105\n",
      "Epoch: 0178 cost= 1.168751995\n",
      "Epoch: 0179 cost= 1.168637117\n",
      "Epoch: 0180 cost= 1.168605394\n",
      "Epoch: 0181 cost= 1.168836342\n",
      "Epoch: 0182 cost= 1.168684138\n",
      "Epoch: 0183 cost= 1.168683608\n",
      "Epoch: 0184 cost= 1.168592082\n",
      "Epoch: 0185 cost= 1.167578088\n",
      "Epoch: 0186 cost= 1.166392061\n",
      "Epoch: 0187 cost= 1.164932648\n",
      "Epoch: 0188 cost= 1.165957252\n",
      "Epoch: 0189 cost= 1.170538757\n",
      "Epoch: 0190 cost= 1.171951850\n",
      "Epoch: 0191 cost= 1.163105342\n",
      "Epoch: 0192 cost= 1.163592418\n",
      "Epoch: 0193 cost= 1.161786437\n",
      "Epoch: 0194 cost= 1.163684805\n",
      "Epoch: 0195 cost= 1.163701309\n",
      "Epoch: 0196 cost= 1.163548324\n",
      "Epoch: 0197 cost= 1.166317913\n",
      "Epoch: 0198 cost= 1.166510423\n",
      "Epoch: 0199 cost= 1.162064128\n",
      "Epoch: 0200 cost= 1.160840935\n",
      "Epoch: 0201 cost= 1.160614583\n",
      "Epoch: 0202 cost= 1.162510329\n",
      "Epoch: 0203 cost= 1.164251698\n",
      "Epoch: 0204 cost= 1.166918092\n",
      "Epoch: 0205 cost= 1.169667496\n",
      "Epoch: 0206 cost= 1.162611405\n",
      "Epoch: 0207 cost= 1.163577014\n",
      "Epoch: 0208 cost= 1.161663824\n",
      "Epoch: 0209 cost= 1.161566509\n",
      "Epoch: 0210 cost= 1.161453790\n",
      "Epoch: 0211 cost= 1.163004557\n",
      "Epoch: 0212 cost= 1.163970325\n",
      "Epoch: 0213 cost= 1.164923231\n",
      "Epoch: 0214 cost= 1.162055916\n",
      "Epoch: 0215 cost= 1.159701162\n",
      "Epoch: 0216 cost= 1.161238035\n",
      "Epoch: 0217 cost= 1.161680500\n",
      "Epoch: 0218 cost= 1.160307580\n",
      "Epoch: 0219 cost= 1.161900202\n",
      "Epoch: 0220 cost= 1.161819776\n",
      "Epoch: 0221 cost= 1.163914614\n",
      "Epoch: 0222 cost= 1.166507019\n",
      "Epoch: 0223 cost= 1.162596239\n",
      "Epoch: 0224 cost= 1.162225803\n",
      "Epoch: 0225 cost= 1.160001410\n",
      "Epoch: 0226 cost= 1.161266300\n",
      "Epoch: 0227 cost= 1.162960821\n",
      "Epoch: 0228 cost= 1.163760834\n",
      "Epoch: 0229 cost= 1.161608722\n",
      "Epoch: 0230 cost= 1.164355874\n",
      "Epoch: 0231 cost= 1.159183409\n",
      "Epoch: 0232 cost= 1.162618068\n",
      "Epoch: 0233 cost= 1.162659857\n",
      "Epoch: 0234 cost= 1.161769973\n",
      "Epoch: 0235 cost= 1.166092475\n",
      "Epoch: 0236 cost= 1.168629726\n",
      "Epoch: 0237 cost= 1.160867903\n",
      "Epoch: 0238 cost= 1.165618062\n",
      "Epoch: 0239 cost= 1.163390795\n",
      "Epoch: 0240 cost= 1.164797836\n",
      "Epoch: 0241 cost= 1.163779603\n",
      "Epoch: 0242 cost= 1.160913772\n",
      "Epoch: 0243 cost= 1.161277480\n",
      "Epoch: 0244 cost= 1.161548681\n",
      "Epoch: 0245 cost= 1.160656253\n",
      "Epoch: 0246 cost= 1.160362018\n",
      "Epoch: 0247 cost= 1.162605577\n",
      "Epoch: 0248 cost= 1.162076606\n",
      "Epoch: 0249 cost= 1.161175688\n",
      "Epoch: 0250 cost= 1.164217710\n",
      "Epoch: 0251 cost= 1.168439878\n",
      "Epoch: 0252 cost= 1.162066340\n",
      "Epoch: 0253 cost= 1.164862778\n",
      "Epoch: 0254 cost= 1.161184722\n",
      "Epoch: 0255 cost= 1.163198339\n",
      "Epoch: 0256 cost= 1.161563820\n",
      "Epoch: 0257 cost= 1.160823319\n",
      "Epoch: 0258 cost= 1.161021696\n",
      "Epoch: 0259 cost= 1.161283824\n",
      "Epoch: 0260 cost= 1.162782232\n",
      "Epoch: 0261 cost= 1.163051446\n",
      "Epoch: 0262 cost= 1.162528462\n",
      "Epoch: 0263 cost= 1.161672393\n",
      "Epoch: 0264 cost= 1.160588357\n",
      "Epoch: 0265 cost= 1.161218630\n",
      "Epoch: 0266 cost= 1.162519150\n",
      "Epoch: 0267 cost= 1.163127674\n",
      "Epoch: 0268 cost= 1.162241671\n",
      "Epoch: 0269 cost= 1.161627226\n",
      "Epoch: 0270 cost= 1.161510163\n",
      "Epoch: 0271 cost= 1.161074400\n",
      "Epoch: 0272 cost= 1.160888486\n",
      "Epoch: 0273 cost= 1.160853730\n",
      "Epoch: 0274 cost= 1.160932276\n",
      "Epoch: 0275 cost= 1.160905984\n",
      "Epoch: 0276 cost= 1.161432385\n",
      "Epoch: 0277 cost= 1.166493098\n",
      "Epoch: 0278 cost= 1.170556625\n",
      "Epoch: 0279 cost= 1.161102957\n",
      "Epoch: 0280 cost= 1.163909621\n",
      "Epoch: 0281 cost= 1.162235273\n",
      "Epoch: 0282 cost= 1.161916865\n",
      "Epoch: 0283 cost= 1.168408434\n",
      "Epoch: 0284 cost= 1.166813056\n",
      "Epoch: 0285 cost= 1.160908169\n",
      "Epoch: 0286 cost= 1.160774403\n",
      "Epoch: 0287 cost= 1.161936561\n",
      "Epoch: 0288 cost= 1.165436572\n",
      "Epoch: 0289 cost= 1.161742237\n",
      "Epoch: 0290 cost= 1.160957774\n",
      "Epoch: 0291 cost= 1.160857585\n",
      "Epoch: 0292 cost= 1.161119117\n",
      "Epoch: 0293 cost= 1.160710944\n",
      "Epoch: 0294 cost= 1.160680453\n",
      "Epoch: 0295 cost= 1.160695553\n",
      "Epoch: 0296 cost= 1.162973179\n",
      "Epoch: 0297 cost= 1.160898156\n",
      "Epoch: 0298 cost= 1.167455369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0299 cost= 1.169204646\n",
      "Epoch: 0300 cost= 1.162804087\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    avg_cost = 0\n",
    "    total_batch = 9\n",
    "    for i in range(total_batch):\n",
    "        feed_dict = {X:Xt[50*i:50*(i+1)], Y:yt[50*i:50*(i+1)]}\n",
    "        c, _ = sess.run([cost,optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "print('Learning finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y_one_hot,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.482222\n",
      "accuracy: 0.456\n"
     ]
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('accuracy:', sess.run(accuracy, feed_dict={X:Xt,Y:yt}))\n",
    "print('accuracy:', sess.run(accuracy, feed_dict={X:Xval,Y:yval}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
